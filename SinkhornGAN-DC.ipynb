{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import sys\n",
    "from utils.show_image import imshow\n",
    "from torchvision import utils\n",
    "from models import Sinkhorn_DCGAN_D,DCGAN_G\n",
    "from utils.sinkhorn_loss import sinkhorn_loss\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda: False\n"
     ]
    }
   ],
   "source": [
    "z_size=100\n",
    "hidden_size=64\n",
    "batch_size = 64\n",
    "dataset_name=\"LSUN\"\n",
    "output_dimension=100\n",
    "niter=100\n",
    "use_cuda=torch.cuda.is_available()\n",
    "print('Use cuda: %r'%use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dataset_name == 'MNIST':\n",
    "    total_epoch=10000\n",
    "    img_size=32\n",
    "    image_chanel = 1\n",
    "    epsilon=0.1\n",
    "    model_name = 'Sinkhorn_DC_MNIST'\n",
    "    root = './data/mnist/'\n",
    "    download = True\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Scale(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    data_set = dset.MNIST(\n",
    "        root=root, transform=trans, download=download)\n",
    "if dataset_name == \"LSUN\":\n",
    "    total_epoch=100000\n",
    "    img_size=64\n",
    "    image_chanel = 3\n",
    "    epsilon=10\n",
    "    model_name = 'Sinkhorn_DC_LSUN'\n",
    "    root = './data/lsun/'\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Scale(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    data_set = dset.LSUN(\n",
    "        db_path=root, classes=['bedroom_train'], transform=trans)\n",
    "if dataset_name == 'CIFAR':\n",
    "    total_epoch=10000\n",
    "    img_size=32\n",
    "    image_chanel = 1\n",
    "    model_name = 'Sinkhorn_DC_CIFAR'\n",
    "    root = './data/cifar10/'\n",
    "    download = True\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Scale(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    data_set = dset.MNIST(\n",
    "        root=root, transform=trans, download=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=data_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "noise_holder=torch.FloatTensor(batch_size, z_size, 1, 1)\n",
    "input_holder = torch.FloatTensor(batch_size, 1, img_size, img_size)\n",
    "if use_cuda:\n",
    "    one=one.cuda()\n",
    "    noise_holder=noise_holder.cuda()\n",
    "    input_holder=input_holder.cuda()\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCGAN_G (\n",
      "  (main): Sequential (\n",
      "    (initial.100-256.convt): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (initial.256.batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (initial.256.relu): ReLU (inplace)\n",
      "    (pyramid.256-128.convt): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (pyramid.128.batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (pyramid.128.relu): ReLU (inplace)\n",
      "    (pyramid.128-64.convt): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (pyramid.64.batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (pyramid.64.relu): ReLU (inplace)\n",
      "    (final.64-1.convt): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (final.1.tanh): Tanh ()\n",
      "  )\n",
      ")\n",
      "Sinkhorn_DCGAN_D (\n",
      "  (main): Sequential (\n",
      "    (initial.conv.1-64): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (initial.relu.64): LeakyReLU (0.2, inplace)\n",
      "    (pyramid.64-128.conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (pyramid.128.batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (pyramid.128.relu): LeakyReLU (0.2, inplace)\n",
      "    (pyramid.128-256.conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (pyramid.256.batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (pyramid.256.relu): LeakyReLU (0.2, inplace)\n",
      "    (final.256-100.conv): Conv2d(256, 100, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "  0%|          | 9/10000 [13:29<249:43:41, 89.98s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected r_ [32 x 32], t [32 x 32] and src [64 x 1] to have the same number of elements, but got 1024, 1024 and 64 elements respectively at /Users/soumith/miniconda2/conda-bld/pytorch_1503975723910/work/torch/lib/TH/generic/THTensorMath.c:887",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0fd8586a157f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./results/%s_%d.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-0fd8586a157f>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mXY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mXX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mYY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/GANs/utils/sinkhorn_loss.py\u001b[0m in \u001b[0;36msinkhorn_loss\u001b[0;34m(x, y, epsilon, n, niter, use_cuda)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m  \u001b[0;31m# useful to check the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# accelerated unbalanced iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/GANs/utils/sinkhorn_loss.py\u001b[0m in \u001b[0;36mM\u001b[0;34m(u, v)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;34m\"Modified cost for logarithmic updates\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m     \u001b[0m__radd__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_add\u001b[0;34m(self, other, inplace)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/basic_ops.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, a, b, inplace)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected r_ [32 x 32], t [32 x 32] and src [64 x 1] to have the same number of elements, but got 1024, 1024 and 64 elements respectively at /Users/soumith/miniconda2/conda-bld/pytorch_1503975723910/work/torch/lib/TH/generic/THTensorMath.c:887"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "G = DCGAN_G(isize=img_size, nz=z_size, nc=image_chanel, ngf=hidden_size, ngpu=0)\n",
    "G.apply(weights_init)\n",
    "D = Sinkhorn_DCGAN_D(isize=img_size, nz=z_size, nc=image_chanel, ndf=hidden_size, ngpu=0, output_dimension=output_dimension)\n",
    "D.apply(weights_init)\n",
    "print(G)\n",
    "print(D)\n",
    "if len(sys.argv)==3:\n",
    "    G.load_state_dict(torch.load(sys.argv[1]))\n",
    "    D.load_state_dict(torch.load(sys.argv[2]))\n",
    "if use_cuda:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "G_lr = D_lr = 5e-5\n",
    "optimizers = {\n",
    "    'D': torch.optim.RMSprop(D.parameters(), lr=D_lr),\n",
    "    'G': torch.optim.RMSprop(G.parameters(), lr=G_lr)\n",
    "}\n",
    "data_iter=iter(data_loader)\n",
    "\n",
    "def training():\n",
    "    for epoch in tqdm(range(total_epoch)):\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = True\n",
    "        if epoch<25 or epoch%500==0:\n",
    "            iter_D=100\n",
    "        else:\n",
    "            iter_D=5\n",
    "        for _ in range(iter_D):\n",
    "            for p in D.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "            optimizers['D'].zero_grad()\n",
    "            try:\n",
    "                data=data_iter.next()[0]\n",
    "            except:\n",
    "                data_iter=iter(data_loader)\n",
    "                data=data_iter.next()[0]\n",
    "            if use_cuda:\n",
    "                data=data.cuda()\n",
    "            input_holder.resize_as_(data).copy_(data)\n",
    "            Y = D(Variable(data))\n",
    "            noise_holder.resize_(data.size()[0], z_size, 1, 1).normal_(0, 1)\n",
    "            noisev = Variable(noise_holder,volatile=True)\n",
    "            fake_data = Variable(G(noisev).data)\n",
    "            X = D(fake_data)\n",
    "            XY=sinkhorn_loss(X,Y,epsilon,batch_size,niter,use_cuda)\n",
    "            XX=sinkhorn_loss(X,X,epsilon,batch_size,niter,use_cuda)\n",
    "            YY=sinkhorn_loss(Y,Y,epsilon,batch_size,niter,use_cuda)\n",
    "            loss_real=2*XY-XX-YY\n",
    "            loss_real.backward(mone)\n",
    "            optimizers['D'].step()\n",
    "\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False\n",
    "        optimizers['G'].zero_grad()\n",
    "        try:\n",
    "            data=data_iter.next()[0]\n",
    "        except:\n",
    "            data_iter=iter(data_loader)\n",
    "            data=data_iter.next()[0]\n",
    "        if use_cuda:\n",
    "            data=data.cuda()\n",
    "        input_holder.resize_as_(data).copy_(data)\n",
    "        Y = D(Variable(data))\n",
    "        noise_holder.resize_(data.size()[0], z_size, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise_holder)\n",
    "        fake_data = G(noisev)\n",
    "        X = D(fake_data)\n",
    "        XY=sinkhorn_loss(X,Y,epsilon,batch_size,niter,use_cuda)\n",
    "        XX=sinkhorn_loss(X,X,epsilon,batch_size,niter,use_cuda)\n",
    "        YY=sinkhorn_loss(Y,Y,epsilon,batch_size,niter,use_cuda)\n",
    "        loss_fake=2*XY-XX-YY\n",
    "        loss_fake.backward(one)\n",
    "        optimizers['G'].step()\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            if use_cuda:\n",
    "                dd = utils.make_grid(fake_data.cpu().data[:64])\n",
    "            else:\n",
    "                dd = utils.make_grid(fake_data.data[:64])\n",
    "            dd = dd.mul(0.5).add(0.5)\n",
    "            vutils.save_image(dd, './results/%s_%d.png'%(model_name,epoch))\n",
    "            torch.save(G.state_dict(), './results/G_epoch_%d.pth'%epoch)\n",
    "            torch.save(D.state_dict(), './results/D_epoch_%d.pth'%epoch)\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
