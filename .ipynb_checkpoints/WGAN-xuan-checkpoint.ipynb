{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf, ngpu):\n",
    "        super(MLP_G, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            # Z goes into a linear of size: ngf\n",
    "            nn.Linear(nz, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ngf, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ngf, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ngf, nc * isize * isize),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.nc = nc\n",
    "        self.isize = isize\n",
    "        self.nz = nz\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), input.size(1))\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output.view(output.size(0), self.nc, self.isize, self.isize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP_D(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ndf, ngpu):\n",
    "        super(MLP_D, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            # Z goes into a linear of size: ndf\n",
    "            nn.Linear(nc * isize * isize, ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ndf, ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ndf, ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ndf, 1),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.nc = nc\n",
    "        self.isize = isize\n",
    "        self.nz = nz\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0),\n",
    "                           input.size(1) * input.size(2) * input.size(3))\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        output = output.mean(0)\n",
    "        return output.view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ndf, ngpu, n_extra_layers=0):\n",
    "        super(DCGAN_D, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is nc x isize x isize\n",
    "        main.add_module('initial.conv.{0}-{1}'.format(nc, ndf),\n",
    "                        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False))\n",
    "        main.add_module('initial.relu.{0}'.format(ndf),\n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "        csize, cndf = isize / 2, ndf\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, cndf),\n",
    "                            nn.Conv2d(cndf, cndf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, cndf),\n",
    "                            nn.BatchNorm2d(cndf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, cndf),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        while csize > 4:\n",
    "            in_feat = cndf\n",
    "            out_feat = cndf * 2\n",
    "            main.add_module('pyramid.{0}-{1}.conv'.format(in_feat, out_feat),\n",
    "                            nn.Conv2d(in_feat, out_feat, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid.{0}.batchnorm'.format(out_feat),\n",
    "                            nn.BatchNorm2d(out_feat))\n",
    "            main.add_module('pyramid.{0}.relu'.format(out_feat),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cndf = cndf * 2\n",
    "            csize = csize / 2\n",
    "\n",
    "        # state size. K x 4 x 4\n",
    "        main.add_module('final.{0}-{1}.conv'.format(cndf, 1),\n",
    "                        nn.Conv2d(cndf, 1, 4, 1, 0, bias=False))\n",
    "        self.main = main\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else: \n",
    "            output = self.main(input)\n",
    "            \n",
    "        output = output.mean(0)\n",
    "        return output.view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf, ngpu, n_extra_layers=0):\n",
    "        super(DCGAN_G, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf//2, 4\n",
    "        while tisize != isize:\n",
    "            cngf = cngf * 2\n",
    "            tisize = tisize * 2\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is Z, going into a convolution\n",
    "        main.add_module('initial.{0}-{1}.convt'.format(nz, cngf),\n",
    "                        nn.ConvTranspose2d(nz, cngf, 4, 1, 0, bias=False))\n",
    "        main.add_module('initial.{0}.batchnorm'.format(cngf),\n",
    "                        nn.BatchNorm2d(cngf))\n",
    "        main.add_module('initial.{0}.relu'.format(cngf),\n",
    "                        nn.ReLU(True))\n",
    "\n",
    "        csize, cndf = 4, cngf\n",
    "        while csize < isize//2:\n",
    "            main.add_module('pyramid.{0}-{1}.convt'.format(cngf, cngf//2),\n",
    "                            nn.ConvTranspose2d(cngf, cngf//2, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid.{0}.batchnorm'.format(cngf//2),\n",
    "                            nn.BatchNorm2d(cngf//2))\n",
    "            main.add_module('pyramid.{0}.relu'.format(cngf//2),\n",
    "                            nn.ReLU(True))\n",
    "            cngf = cngf // 2\n",
    "            csize = csize * 2\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, cngf),\n",
    "                            nn.Conv2d(cngf, cngf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, cngf),\n",
    "                            nn.BatchNorm2d(cngf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, cngf),\n",
    "                            nn.ReLU(True))\n",
    "\n",
    "        main.add_module('final.{0}-{1}.convt'.format(cngf, nc),\n",
    "                        nn.ConvTranspose2d(cngf, nc, 4, 2, 1, bias=False))\n",
    "        main.add_module('final.{0}.tanh'.format(nc),\n",
    "                        nn.Tanh())\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else: \n",
    "            output = self.main(input)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngpu = 1 # number of GPUs to use\n",
    "nz = 100 # size of the latent z vector\n",
    "ngf = 512\n",
    "ndf = 512\n",
    "nc = 1 # input image channels\n",
    "n_extra_layers = 0 # Number of extra layers on gen and disc\n",
    "\n",
    "imageSize = 28\n",
    "batchSize = 100\n",
    "n_workers = 2\n",
    "\n",
    "\n",
    "adam = False\n",
    "lrD = 0.00005\n",
    "lrG = 0.00005\n",
    "\n",
    "beta1 = 0.5 # beta1 for adam. default=0.5\n",
    "niter = 500 # number of epochs to train for\n",
    "Diters = 5 #number of D iters per each G iter\n",
    "\n",
    "\n",
    "\n",
    "clamp_lower = -0.01\n",
    "clamp_upper = 0.01\n",
    "\n",
    "experiment = './results' # Where to store samples and models\n",
    "\n",
    "epsilon = 1 # panalty weight\n",
    "L = 10 # sinkhorn iteration num\n",
    "\n",
    "netG_path = ''\n",
    "netD_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "dataset = dset.MNIST(root='./data', download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(imageSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_G (\n",
      "  (main): Sequential (\n",
      "    (0): Linear (100 -> 512)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): Linear (512 -> 512)\n",
      "    (3): ReLU (inplace)\n",
      "    (4): Linear (512 -> 512)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (512 -> 784)\n",
      "  )\n",
      ")\n",
      "MLP_D (\n",
      "  (main): Sequential (\n",
      "    (0): Linear (784 -> 512)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): Linear (512 -> 512)\n",
      "    (3): ReLU (inplace)\n",
      "    (4): Linear (512 -> 512)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (512 -> 1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = MLP_G(imageSize, nz, nc, ngf, ngpu)\n",
    "netD = MLP_D(imageSize, nz, nc, ndf, ngpu)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "if netG_path != '': # load checkpoint if needed\n",
    "    netG.load_state_dict(torch.load(netG_path))\n",
    "print(netG)\n",
    "\n",
    "netD.apply(weights_init)\n",
    "if netD_path != '':\n",
    "    netD.load_state_dict(torch.load(netD_path))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batchSize, 3, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if adam:\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lrD, betas=(beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lrG, betas=(beta1, 0.999))\n",
    "else:\n",
    "    optimizerD = optim.RMSprop(netD.parameters(), lr = lrD)\n",
    "    optimizerG = optim.RMSprop(netG.parameters(), lr = lrG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/500][100/600][1] Loss_D: -120.178391 Loss_G: -5.137172 Loss_D_real: -125.154549 Loss_D_fake -4.976161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/datasets/mnist.py\", line 75, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms.py\", line 81, in __call__\n",
      "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6108b6fd88d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# train with fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import Tracer\n",
    "gen_iterations = 0\n",
    "for epoch in range(niter):\n",
    "    #Tracer()()\n",
    "    data_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    while i < len(dataloader):\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "\n",
    "        # train the discriminator Diters times\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            Diters = 100\n",
    "        #else:\n",
    "        #    Diters = opt.Diters\n",
    "        j = 0\n",
    "        while j < Diters and i < len(dataloader):\n",
    "            j += 1\n",
    "\n",
    "            # clamp parameters to a cube\n",
    "            for p in netD.parameters():\n",
    "                p.data.clamp_(clamp_lower, clamp_upper)\n",
    "\n",
    "            data = data_iter.next()\n",
    "            i += 1\n",
    "\n",
    "            # train with real\n",
    "            real_cpu, _ = data\n",
    "            netD.zero_grad()\n",
    "            batch_size = real_cpu.size(0)\n",
    "\n",
    "            #if opt.cuda:\n",
    "            #    real_cpu = real_cpu.cuda()\n",
    "            input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "            inputv = Variable(input)\n",
    "\n",
    "            errD_real = netD(inputv)\n",
    "            errD_real.backward(one)\n",
    "\n",
    "            # train with fake\n",
    "            noise.resize_(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "            noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "            inputv = fake\n",
    "            errD_fake = netD(inputv)\n",
    "            errD_fake.backward(mone)\n",
    "            errD = errD_real - errD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False # to avoid computation\n",
    "        netG.zero_grad()\n",
    "        # in case our last batch was the tail batch of the dataloader,\n",
    "        # make sure we feed a full batch of noise\n",
    "        noise.resize_(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        errG = netD(fake)\n",
    "        errG.backward(one)\n",
    "        optimizerG.step()\n",
    "        gen_iterations += 1\n",
    "\n",
    "        print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, niter, i, len(dataloader), gen_iterations,\n",
    "            errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))\n",
    "        if gen_iterations % 100 == 0:\n",
    "            real_cpu = real_cpu.mul(0.5).add(0.5)\n",
    "            vutils.save_image(real_cpu, '{0}/real_samples.png'.format(experiment))\n",
    "            fake = netG(Variable(fixed_noise, volatile=True))\n",
    "            fake.data = fake.data.mul(0.5).add(0.5)\n",
    "            vutils.save_image(fake.data, '{0}/fake_samples_{1}.png'.format(experiment, gen_iterations))\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '{0}/WGANnetG_epoch_{1}.pth'.format(experiment, epoch))\n",
    "    torch.save(netD.state_dict(), '{0}/WGANnetD_epoch_{1}.pth'.format(experiment, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "noise.resize_(16, nz, 1, 1).normal_(0, 1)\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)\n",
    "fake = fake.mul(0.5).add(0.5)\n",
    "fake = fake - fake.min()\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "def imshow(inp, save=False, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp,cmap='gray')\n",
    "    plt.show()\n",
    "dd = utils.make_grid(fake.data)\n",
    "imshow(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
