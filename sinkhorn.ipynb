{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 84,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from IPython.core.debugger import Tracer\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 85,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "def imshow(inp, save=False, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    inp = transforms.ToPILImage()(inp)\n",
    "    plt.imshow(inp,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 86,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "class MLP_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf, ngpu):\n",
    "        super(MLP_G, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            # Z goes into a linear of size: ngf\n",
    "            nn.Linear(nz, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ngf, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ngf, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ngf, nc * isize * isize),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.nc = nc\n",
    "        self.isize = isize\n",
    "        self.nz = nz\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), input.size(1))\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output.view(output.size(0), self.nc, self.isize, self.isize)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 87,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "class MLP_D(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ndf, ngpu):\n",
    "        super(MLP_D, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            # Z goes into a linear of size: ndf\n",
    "            nn.Linear(nc * isize * isize, ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ndf, ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ndf, ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(ndf, 1),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.nc = nc\n",
    "        self.isize = isize\n",
    "        self.nz = nz\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0),\n",
    "                           input.size(1) * input.size(2) * input.size(3))\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        output = output.mean(0)\n",
    "        return output.view(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 88,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ndf, ngpu, n_extra_layers=0):\n",
    "        super(DCGAN_D, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is nc x isize x isize\n",
    "        main.add_module('initial.conv.{0}-{1}'.format(nc, ndf),\n",
    "                        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False))\n",
    "        main.add_module('initial.relu.{0}'.format(ndf),\n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "        csize, cndf = isize / 2, ndf\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, cndf),\n",
    "                            nn.Conv2d(cndf, cndf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, cndf),\n",
    "                            nn.BatchNorm2d(cndf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, cndf),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        while csize > 4:\n",
    "            in_feat = cndf\n",
    "            out_feat = cndf * 2\n",
    "            main.add_module('pyramid.{0}-{1}.conv'.format(in_feat, out_feat),\n",
    "                            nn.Conv2d(in_feat, out_feat, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid.{0}.batchnorm'.format(out_feat),\n",
    "                            nn.BatchNorm2d(out_feat))\n",
    "            main.add_module('pyramid.{0}.relu'.format(out_feat),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cndf = cndf * 2\n",
    "            csize = csize / 2\n",
    "\n",
    "        # state size. K x 4 x 4\n",
    "        main.add_module('final.{0}-{1}.conv'.format(cndf, 1),\n",
    "                        nn.Conv2d(cndf, 1, 4, 1, 0, bias=False))\n",
    "        self.main = main\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else: \n",
    "            output = self.main(input)\n",
    "            \n",
    "        output = output.mean(0)\n",
    "        return output.view(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 89,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf, ngpu, n_extra_layers=0):\n",
    "        super(DCGAN_G, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf//2, 4\n",
    "        while tisize != isize:\n",
    "            cngf = cngf * 2\n",
    "            tisize = tisize * 2\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is Z, going into a convolution\n",
    "        main.add_module('initial.{0}-{1}.convt'.format(nz, cngf),\n",
    "                        nn.ConvTranspose2d(nz, cngf, 4, 1, 0, bias=False))\n",
    "        main.add_module('initial.{0}.batchnorm'.format(cngf),\n",
    "                        nn.BatchNorm2d(cngf))\n",
    "        main.add_module('initial.{0}.relu'.format(cngf),\n",
    "                        nn.ReLU(True))\n",
    "\n",
    "        csize, cndf = 4, cngf\n",
    "        while csize < isize//2:\n",
    "            main.add_module('pyramid.{0}-{1}.convt'.format(cngf, cngf//2),\n",
    "                            nn.ConvTranspose2d(cngf, cngf//2, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid.{0}.batchnorm'.format(cngf//2),\n",
    "                            nn.BatchNorm2d(cngf//2))\n",
    "            main.add_module('pyramid.{0}.relu'.format(cngf//2),\n",
    "                            nn.ReLU(True))\n",
    "            cngf = cngf // 2\n",
    "            csize = csize * 2\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, cngf),\n",
    "                            nn.Conv2d(cngf, cngf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, cngf),\n",
    "                            nn.BatchNorm2d(cngf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, cngf),\n",
    "                            nn.ReLU(True))\n",
    "\n",
    "        main.add_module('final.{0}-{1}.convt'.format(cngf, nc),\n",
    "                        nn.ConvTranspose2d(cngf, nc, 4, 2, 1, bias=False))\n",
    "        main.add_module('final.{0}.tanh'.format(nc),\n",
    "                        nn.Tanh())\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else: \n",
    "            output = self.main(input)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 90,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "def cost_matrix(x, y,p=2) :\n",
    "    \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "    x_col = x.unsqueeze(1) \n",
    "    y_lin = y.unsqueeze(0)\n",
    "    c = torch.sum( (torch.abs(x_col - y_lin))**p , 2) \n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 101,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "def sinkhorn_loss(x,y,epsilon,n,niter) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Given two emprical measures with n points each with locations x and y \n",
    "    outputs an approximation of the OT cost with regularization parameter epsilon\n",
    "    niter is the max. number of steps in sinkhorn loop\n",
    "    \"\"\"\n",
    "    # The Sinkhorn algorithm takes as input three variables :\n",
    "    C = cost_matrix(x, y) # Wasserstein cost function\n",
    "    # both marginals are fixed with equal weights\n",
    "    if cuda and torch.cuda.is_available():\n",
    "        mu = Variable(1./n*torch.cuda.FloatTensor(n).fill_(1),requires_grad=False) \n",
    "        nu = Variable(1./n*torch.cuda.FloatTensor(n).fill_(1),requires_grad=False)\n",
    "    else:\n",
    "        mu = Variable(1./n*torch.FloatTensor(n).fill_(1),requires_grad=False) \n",
    "        nu = Variable(1./n*torch.FloatTensor(n).fill_(1),requires_grad=False)\n",
    "    \n",
    "    # Parameters of the Sinkhorn algorithm.\n",
    "    rho                = 1 #(.5) **2          # unbalanced transport \n",
    "    tau                = -.8               # nesterov-like acceleration\n",
    "    lam = rho / (rho + epsilon)            # Update exponent\n",
    "    thresh = 10**(-1)                   # stopping criterion\n",
    "\n",
    "    # Elementary operations .....................................................................\n",
    "    def ave(u,u1) : \n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1-tau) * u1 \n",
    "\n",
    "    def M(u,v)  : \n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(1) + v.unsqueeze(0)) / epsilon\n",
    "\n",
    "    def lse(A) :\n",
    "        \"log-sum-exp\" \n",
    "        return torch.log(torch.exp(A).sum( 1, keepdim = True ) + 1e-6) # add 10^-6 to prevent NaN\n",
    "    \n",
    "    # Actual Sinkhorn loop ......................................................................\n",
    "    u,v,err = epsilon * torch.log(mu), epsilon * torch.log(nu), 0.\n",
    "    actual_nits = 0 # to check if algorithm terminates because of threshold or max iterations reached\n",
    "    \n",
    "    for i in range(niter) :\n",
    "        u1 = u # useful to check the update\n",
    "        #Tracer()()\n",
    "        u =  epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze() ) + u\n",
    "        v =  epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze()) + v\n",
    "        #u = epsilon * (torch.log(mu) - (-C/epsilon + epsilon * ) / epsilon + 1e-6 ))\n",
    "        # accelerated unbalanced iterations \n",
    "        #u = ave( u, lam * ( epsilon * ( torch.log(mu.unsqueeze(1)) - lse(M(u,v))   ) + u ) )\n",
    "        #v = ave( v, lam * ( epsilon * ( torch.log(nu.unsqueeze(1)) - lse(M(u,v).t()) ) + v ) )\n",
    "        #err = (u - u1).abs().sum()\n",
    "        #actual_nits += 1\n",
    "        #if (err < thresh).data.cpu().numpy() :\n",
    "        #    break\n",
    "    U, V = u, v \n",
    "    #Tracer()()\n",
    "    logC = torch.log(C + 1e-5)\n",
    "    logpi = M(U,V)\n",
    "    #pi = torch.exp( M(U,V) ) # Transport plan pi = diag(a)*K*diag(b)\n",
    "    #cost  = torch.sum(pi * C)        # Sinkhorn cost\n",
    "    cost = torch.sum(torch.exp(logpi + logC))\n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 92,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "def sinkhorn_normalized(x,y,epsilon,n,niter):\n",
    "\n",
    "    x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "    y = y.view(y.size(0), y.size(1) * y.size(2) * y.size(3))\n",
    "    Wxy = sinkhorn_loss(x,y,epsilon,n,niter)\n",
    "    Wxx = sinkhorn_loss(x,x,epsilon,n,niter)\n",
    "    Wyy = sinkhorn_loss(y,y,epsilon,n,niter)\n",
    "    return 2*Wxy - Wxx - Wyy "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 93,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "ngpu = 1 # number of GPUs to use\n",
    "nz = 100 # size of the latent z vector\n",
    "ngf = 512\n",
    "ndf = 512\n",
    "nc = 1 # input image channels\n",
    "n_extra_layers = 0 # Number of extra layers on gen and disc\n",
    "\n",
    "imageSize = 28\n",
    "batchSize = 200\n",
    "n_workers = 2\n",
    "\n",
    "\n",
    "adam = False\n",
    "lrG = 0.005\n",
    "\n",
    "beta1 = 0.5 # beta1 for adam. default=0.5\n",
    "niter = 2 # number of epochs to train for\n",
    "\n",
    "clamp_lower = -0.1\n",
    "clamp_upper = 0.1\n",
    "\n",
    "experiment = './experiment' # Where to store samples and models\n",
    "\n",
    "epsilon = 1 # panalty weight\n",
    "L = 10 # sinkhorn iteration num\n",
    "\n",
    "netG_path = experiment + '/netG_sinkhorn.pth'\n",
    "netD_path = ''\n",
    "\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 94,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "# get data\n",
    "dataset = dset.MNIST(root='./data', download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(imageSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 95,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 103,
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_G (\n",
      "  (main): Sequential (\n",
      "    (0): Linear (100 -> 512)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): Linear (512 -> 512)\n",
      "    (3): ReLU (inplace)\n",
      "    (4): Linear (512 -> 512)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (512 -> 784)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = MLP_G(imageSize, nz, nc, ngf, ngpu)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "try: # load checkpoint if needed\n",
    "    netG.load_state_dict(torch.load(netG_path))\n",
    "    print(\"load parameters\")\n",
    "except:\n",
    "    pass\n",
    "print(netG)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 97,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batchSize, 3, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 98,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "if cuda and torch.cuda.is_available():\n",
    "    netG.cuda()\n",
    "    input = input.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 99,
   "metadata": {},
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "outputs": [],
   "source": [
    "if adam:\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lrG, betas=(beta1, 0.999))\n",
    "else:\n",
    "    optimizerG = optim.RMSprop(netG.parameters(), lr = lrG)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": null,
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[0/2][0/300][1] Sinkhorn_Loss: -0.000020\n",
      "[0/2][1/300][2] Sinkhorn_Loss: -0.000020\n",
      "[0/2][2/300][3] Sinkhorn_Loss: -0.000020\n",
      "[0/2][3/300][4] Sinkhorn_Loss: -0.000020\n",
      "[0/2][4/300][5] Sinkhorn_Loss: -0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/sunxiaofei/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4adb2030decc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0minputv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn_normalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#- compute_sinkhorn_loss(batchSize, fake, fake, epsilon, L) - compute_sinkhorn_loss(batchSize, inputv, inputv, epsilon, L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-596761a8dfa0>\u001b[0m in \u001b[0;36msinkhorn_normalized\u001b[0;34m(x, y, epsilon, n, niter)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mWxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mWxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mWyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f7c7498609de>\u001b[0m in \u001b[0;36msinkhorn_loss\u001b[0;34m(x, y, epsilon, n, niter)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# The Sinkhorn algorithm takes as input three variables :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Wasserstein cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# both marginals are fixed with equal weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8dd61be39e33>\u001b[0m in \u001b[0;36mcost_matrix\u001b[0;34m(x, y, p)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_col\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_lin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, dim, keepdim)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/reduce.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, dim, keepdim)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
      "[0/2][0/300][1] Sinkhorn_Loss: -1.024344\n",
      "[0/2][1/300][2] Sinkhorn_Loss: -1.004758\n",
      "[0/2][2/300][3] Sinkhorn_Loss: -1.003571\n",
      "[0/2][3/300][4] Sinkhorn_Loss: -0.969569\n",
      "[0/2][4/300][5] Sinkhorn_Loss: -1.029820\n",
      "[0/2][5/300][6] Sinkhorn_Loss: -0.993362\n",
      "[0/2][6/300][7] Sinkhorn_Loss: -1.008217\n",
      "[0/2][7/300][8] Sinkhorn_Loss: -1.038788\n",
      "[0/2][8/300][9] Sinkhorn_Loss: -1.012908\n",
      "[0/2][9/300][10] Sinkhorn_Loss: -1.016588\n",
      "[0/2][10/300][11] Sinkhorn_Loss: -1.011467\n",
      "[0/2][11/300][12] Sinkhorn_Loss: -1.003042\n",
      "[0/2][12/300][13] Sinkhorn_Loss: -1.014480\n",
      "[0/2][13/300][14] Sinkhorn_Loss: -0.987950\n",
      "[0/2][14/300][15] Sinkhorn_Loss: -1.002742\n",
      "[0/2][15/300][16] Sinkhorn_Loss: -1.031318\n",
      "[0/2][16/300][17] Sinkhorn_Loss: -1.005393\n",
      "[0/2][17/300][18] Sinkhorn_Loss: -0.975767\n",
      "[0/2][18/300][19] Sinkhorn_Loss: -1.034556\n",
      "[0/2][19/300][20] Sinkhorn_Loss: -1.018026\n",
      "[0/2][20/300][21] Sinkhorn_Loss: -1.007169\n",
      "[0/2][21/300][22] Sinkhorn_Loss: -1.025716\n",
      "[0/2][22/300][23] Sinkhorn_Loss: -1.009599\n",
      "[0/2][23/300][24] Sinkhorn_Loss: -1.029072\n",
      "[0/2][24/300][25] Sinkhorn_Loss: -0.987479\n",
      "[0/2][25/300][26] Sinkhorn_Loss: -0.998002\n",
      "[0/2][26/300][27] Sinkhorn_Loss: -0.980368\n",
      "[0/2][27/300][28] Sinkhorn_Loss: -1.002404\n",
      "[0/2][28/300][29] Sinkhorn_Loss: -1.031533\n",
      "[0/2][29/300][30] Sinkhorn_Loss: -1.003962\n",
      "[0/2][30/300][31] Sinkhorn_Loss: -1.024657\n",
      "[0/2][31/300][32] Sinkhorn_Loss: -1.009598\n",
      "[0/2][32/300][33] Sinkhorn_Loss: -1.020637\n",
      "[0/2][33/300][34] Sinkhorn_Loss: -1.000265\n",
      "[0/2][34/300][35] Sinkhorn_Loss: -1.023172\n",
      "[0/2][35/300][36] Sinkhorn_Loss: -1.030207\n",
      "[0/2][36/300][37] Sinkhorn_Loss: -1.013189\n",
      "[0/2][37/300][38] Sinkhorn_Loss: -1.012945\n",
      "[0/2][38/300][39] Sinkhorn_Loss: -1.017897\n",
      "[0/2][39/300][40] Sinkhorn_Loss: -0.996592\n",
      "[0/2][40/300][41] Sinkhorn_Loss: -1.009692\n",
      "[0/2][41/300][42] Sinkhorn_Loss: -0.996303\n",
      "[0/2][42/300][43] Sinkhorn_Loss: -0.980310\n",
      "[0/2][43/300][44] Sinkhorn_Loss: -0.984757\n",
      "[0/2][44/300][45] Sinkhorn_Loss: -1.003133\n",
      "[0/2][45/300][46] Sinkhorn_Loss: -1.012662\n",
      "[0/2][46/300][47] Sinkhorn_Loss: -0.997720\n",
      "[0/2][47/300][48] Sinkhorn_Loss: -1.038579\n",
      "[0/2][48/300][49] Sinkhorn_Loss: -0.995551\n",
      "[0/2][49/300][50] Sinkhorn_Loss: -1.007602\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAABqCAYAAAAhpe1YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a14ca4b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2][50/300][51] Sinkhorn_Loss: -0.994626\n"
>>>>>>> e3310bc932d36beac1b71fd43153fd16a19ca29f
     ]
    }
   ],
   "source": [
    "\n",
    "gen_iterations = 0\n",
    "for epoch in range(niter):\n",
    "    \n",
    "    data_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    while i < len(dataloader):\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        data = data_iter.next()\n",
    "        real_cpu, _ = data\n",
    "        if cuda and torch.cuda.is_available():\n",
    "            real_cpu = real_cpu.cuda()\n",
    "        netG.zero_grad()\n",
    "        # in case our last batch was the tail batch of the dataloader,\n",
    "        # make sure we feed a full batch of noise\n",
    "        noise.resize_(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "        if cuda and torch.cuda.is_available():\n",
    "            noise = noise.cuda()\n",
    "        noisev = Variable(noise, requires_grad = False)\n",
    "        fake = netG(noisev)\n",
    "        #Tracer()()\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        inputv = Variable(input, requires_grad = False)\n",
    "        loss = sinkhorn_normalized(fake, inputv, epsilon, batchSize, L) #- compute_sinkhorn_loss(batchSize, fake, fake, epsilon, L) - compute_sinkhorn_loss(batchSize, inputv, inputv, epsilon, L)\n",
    "        loss.backward(one)\n",
    "        optimizerG.step()\n",
    "        gen_iterations += 1\n",
    "        print('[%d/%d][%d/%d][%d] Sinkhorn_Loss: %f'\n",
    "            % (epoch, niter, i, len(dataloader), gen_iterations,\n",
    "            loss.data[0]))\n",
    "        if gen_iterations % 50 == 0:\n",
    "            real_cpu = real_cpu.mul(0.5).add(0.5)\n",
    "            vutils.save_image(real_cpu, '{0}/real_samples_sinkhorn.png'.format(experiment))\n",
    "            fake = netG(Variable(fixed_noise, volatile=True))\n",
    "            fake.data = fake.data.mul(0.5).add(0.5)\n",
    "            vutils.save_image(fake.data, '{0}/fake_samples_sinkhorn.png'.format(experiment))\n",
    "            if cuda and torch.cuda.is_available():\n",
    "                dd = utils.make_grid(fake.cpu().data[:16])\n",
    "            else:\n",
    "                dd = utils.make_grid(fake.data[:16]) \n",
    "            imshow(dd)\n",
    "            # do checkpointing\n",
    "            torch.save(netG.state_dict(), '{0}/netG_sinkhorn.pth'.format(experiment))\n",
    "        i += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
